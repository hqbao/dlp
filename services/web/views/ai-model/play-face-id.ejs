<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="/bootstrap/css/bootstrap.css">
    <script src="https://code.jquery.com/jquery-3.2.1.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"></script>
    <script src="/bootstrap/js/bootstrap.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@2.7.0/dist/tf.min.js"></script>
    <title>DLP - AI Model</title>
  </head>
  <body>
    <nav class="navbar navbar-expand-lg navbar-light bg-light">
      <a class="navbar-brand" href="/">DLP</a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav mr-auto">
          <li class="nav-item">
            <a class="nav-link" href="/user/profile">MY PROFILE</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="/ai-model/list">MY MODELS</a>
          </li>
        </ul>
        <form class="form-inline my-2 my-lg-0">
          <input class="form-control mr-sm-2" type="search" placeholder="Search" aria-label="Search">
          <button class="btn btn-outline-info my-2 my-sm-0" type="submit">Search</button>
        </form>
      </div>
    </nav>
    <br>
    <div class="container-fluid">
      <div class="row">
        <div class="col-12">
          <div style="max-width: 256px;margin: auto;">
            <video width="256" height="256" style="position: fixed;background-color: black;z-index: 1;"></video>
            <canvas id="overlay" width="256" height="256" style="position: relative;left: 0px;background-color: none;z-index: 2;">
          </div>
        </div>
        <div class="col-12">
          <div style="max-width: 256px;margin: auto;">
            <button style="width: 100%;" class="btn btn-success mb-2" onclick="onStartClicked()">Start</button>
            <button style="width: 100%;" class="btn btn-danger mb-2" onclick="onStopClicked()">Stop</button>
            <button style="width: 100%;" class="btn btn-warning mb-2" onclick="idgen()">Update face ID</button>
            <button style="width: 100%;" class="btn btn-warning mb-2" onclick="clearFaceId()">Clear face ID</button>
          </div>
        </div>
      </div>
    </div>
    <div style="height: 660px;width: 330px;position: fixed;left: -16px;top: 64px;overflow: auto;direction: rtl;">
      <ul id="tempItem" class="list-group" style="display: none;">
        <li class="list-group-item">
          <div style="float: left;">{IMAGE_TAG}</div>
          <div style="float: left;margin-left: 8px;">
            <input type="text" class="form-control form-control-sm" value="{NAME}" style="max-width: 100px;">
            <a href="javascript:void(0)" class="badge bg-warning text-dark" onclick="onLabelClicked(this)">LABEL</a>
          </div>
        </li>
      </ul>
      <ul id="itemList" class="list-group" style="direction: ltr;"></ul>
    </div>
    <script type="text/javascript" src="/js/global.js"></script>
    <script type="text/javascript">
      var gVideo = document.querySelector('video');
      var isVideoReady = false;

      var detectorCanvas = document.createElement('canvas');
      var detectorCtx = detectorCanvas.getContext('2d');

      var croppingCanvas = document.createElement('canvas');
      var croppingCtx = croppingCanvas.getContext('2d');

      var overlayCanvas = document.getElementById('overlay');
      var overlayCtx = overlayCanvas.getContext('2d');

      var faceDetectionModel = null;
      var faceIdModel = null;
      var aiModelId = getParamInUrl('id');
      var faceIdModel = null;
      var inference = false;
      var infering = false;

      var faceListElem = document.getElementById('itemList');

      var gEmbeddingDict = {};

      function clearFaceId() {
        confirm('Are you sure?')
        localStorage.setItem('FACEID_EMBEDDING_DICT', null);
        localStorage.setItem('FACEID_LABELED_FACE_DICT', null);
      }

      function loadEmbeddingDict() {
        try { var gEmbeddingDict = JSON.parse(localStorage.getItem('FACEID_EMBEDDING_DICT')); } catch(e) {}
        if (!gEmbeddingDict) { gEmbeddingDict = {}; }
        return gEmbeddingDict;
      }

      function idgen() {
        var embeddingDict = {};

        try { var labeledFaceDict = JSON.parse(localStorage.getItem('FACEID_LABELED_FACE_DICT')); } catch(e) {}
        for (id in labeledFaceDict) {
          var labeledFaces = labeledFaceDict[id];
          var imageTensor = tf.tensor4d(labeledFaces);
          imageTensor = tf.image.resizeBilinear(imageTensor, [112, 112]);
          var inputTensor = tf.cast(imageTensor, 'float32');
          var embeddings = faceIdModel.execute(inputTensor);
          var embedding = embeddings.mean(0);
          var embeddingArray = embedding.arraySync();

          embeddingDict[id] = embeddingArray;
        }

        localStorage.setItem('FACEID_EMBEDDING_DICT', JSON.stringify(embeddingDict));
      }

      function onLabelClicked(self) {
        self.style.display = 'none';

        var id = self.previousElementSibling.value;
        var imgElement = self.parentElement.previousElementSibling.firstElementChild;

        var imageTensor = tf.browser.fromPixels(imgElement);
        imageTensor = tf.cast(imageTensor, 'float32');
        var imageArray = imageTensor.arraySync();

        try { var labeledFaceDict = JSON.parse(localStorage.getItem('FACEID_LABELED_FACE_DICT')); } catch(e) {}
        if (!labeledFaceDict) { labeledFaceDict = {}; }
        if (!(id in labeledFaceDict)) { labeledFaceDict[id] = []; }
        labeledFaceDict[id].push(imageArray);
        localStorage.setItem('FACEID_LABELED_FACE_DICT', JSON.stringify(labeledFaceDict));

        // Store in server
        // storeImageInServer(imgElement);
      }

      function storeImageInServer(imgElement) {
        fetch(imgElement.src)
        .then(res => res.blob())
        .then(blob => {
          const file = new File([blob], id+'.png', blob);

          var params = {
            id: id,
            file: file,
          }

          restapi.uploadFaceId('', '/upload/faceid', null, params, localStorage.getItem('TOKEN'), '/sign-in', function(msgResp) {
            var zipFaceidUrl = msgResp.url;

          }, function(msg) {
            console.log(msg);
          });
        });
      }

      function recognize(embeddingDict, embedding) {
        var embeddingTensor = tf.tensor1d(embedding);
        var minDistance = 1.0;
        var id = 'Unknown';
        for (_id in embeddingDict) {
          var _embedding = embeddingDict[_id];
          var _embeddingTensor = tf.tensor1d(_embedding);
          var distanceTensor = tf.norm(tf.sub(embeddingTensor, _embeddingTensor));
          var distance = distanceTensor.arraySync();
          console.log(distance);
          if (distance < minDistance) {
            minDistance = distance;
            id = _id;
          }
        }

        return id;
      }

      function updateFaceList(croppedCanvas, name) {
        croppedCanvas.toBlob(function(blob) {
          // Create image
          var croppedImage = new Image();
          croppedImage.height = croppedCanvas.height;
          croppedImage.width = croppedCanvas.width;
          croppedImage.src = URL.createObjectURL(blob);

          var imageWrapper = document.createElement('div');
          imageWrapper.appendChild(croppedImage);

          var tempItem = document.getElementById('tempItem').cloneNode(true);
          var html = tempItem.innerHTML;
          html = html.replaceAll('{IMAGE_TAG}', imageWrapper.innerHTML);
          html = html.replaceAll('{NAME}', name);
          tempItem.innerHTML = html;

          if (faceListElem.childNodes.length > 16) {
            faceListElem.removeChild(faceListElem.childNodes[faceListElem.childNodes.length-1]);
          }

          faceListElem.insertBefore(tempItem.firstElementChild, faceListElem.firstChild);
        }, 'image/jpeg');
      }

      function drawBoxWithText(box, text) {
        overlayCtx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);

        overlayCtx.beginPath();
        overlayCtx.strokeStyle = "#FFFFFF";
        overlayCtx.rect(box[1], box[0], (box[3]-box[1]), (box[2]-box[0]), Math.PI);
        overlayCtx.stroke();

        overlayCtx.font = "16px Arial";
        overlayCtx.fillStyle = "#FFFFFF";
        overlayCtx.fillText(text, box[1]-4, box[0]-4);
      }

      function inferFaceId(croppedCanvas, croppedFaceBox, onFaceRecognized) {
        var pix = tf.browser.fromPixels(croppedCanvas);
        pix = tf.image.resizeBilinear(pix, [112, 112]);
        // console.log(JSON.stringify(pix.arraySync()));
        pix = tf.cast(pix, 'float32');
        pix = pix.expandDims(0);
        var prediction = faceIdModel.execute(pix);
        var embedding = prediction.arraySync()[0];

        // Recognize
        var name = recognize(gEmbeddingDict, embedding);
        onFaceRecognized(name);
      }

      function handleFaceDetection(validOutputs, boxes, boxIdx, onFaceDetected) {
        if (boxIdx >= validOutputs) {
          onFaceDetected(null, null, null);
          return;
        }

        function next() {
          handleFaceDetection(validOutputs, boxes, boxIdx+1, onFaceDetected);
        }

        var box = boxes[boxIdx];
        var h = box[2] - box[0];
        var w = box[3] - box[1];
        var size = h > w ? h : w;
        size *= 1.2;

        croppingCanvas.height = size;
        croppingCanvas.width = size;
        croppingCtx.drawImage(detectorCanvas, -(box[1]+0.5*(box[3]-box[1])-0.5*size), -(box[0]+0.5*(box[2]-box[0])-0.5*size));
        onFaceDetected(croppingCanvas, box, next);
      }

      async function inferFaceDetection(onFaceDetected) {
        var pix = tf.browser.fromPixels(detectorCanvas);
        pix = tf.image.resizeBilinear(pix, [256, 256]);
        pix = tf.cast(pix, 'float32');
        pix = pix.expandDims(0);
        var prediction = await faceDetectionModel.executeAsync(pix); // TFJS not working with tensorflow 2.4
        
        var output1 = prediction[0].arraySync();
        var output2 = prediction[1].arraySync();
        if (Array.isArray(output1[0])) {
          validOutputs = output2[0];
          boxes = output1;
        }
        else {
          validOutputs = output1[0];
          boxes = output2;
        }

        handleFaceDetection(validOutputs, boxes, 0, onFaceDetected);
      }

      function loadedmetadata(e) {}

      function timeupdate(e) {
        detectorCanvas.height = 256;
        detectorCanvas.width = 256;
        detectorCtx.drawImage(this, 0, 0);
      }

      function ended(e) {}

      gVideo.addEventListener('loadedmetadata', loadedmetadata, false);
      gVideo.addEventListener('timeupdate', timeupdate, false);
      gVideo.addEventListener('ended', ended, false);

      function onStopClicked() {
        if (isVideoReady) {
          gVideo.pause();
          inference = false;
        }
      }

      function onStartClicked() {
        if (isVideoReady) {
          gVideo.play();
          inference = true;
        }
      }

      function play() {
        var constraints = {audio: false, video: {width: 256, height: 256}};
        navigator.mediaDevices.getUserMedia(constraints)
        .then(function(mediaStream) {
          gVideo.srcObject = mediaStream;
          gVideo.onloadedmetadata = function(e) {
            isVideoReady = true;
          };
        })
        .catch(function(err) { 
          console.log(err.name + ": " + err.message); 
        });
      }
      
      function load() {
        restapi.get(DLPS_URL, '/api/aimodel/detail', {id: aiModelId}, localStorage.getItem('TOKEN'), '/sign-in', async function(msgResp) {
          var model = msgResp;
          faceIdModel = await tf.loadGraphModel(model.tfjsModelUrl);
          faceDetectionModel = await tf.loadGraphModel(DLPS_URL+'/tfjs/face-detection/model.json');
          gEmbeddingDict = loadEmbeddingDict();
          play();
        }, function(msg) {
          console.log(msg);
        });
      }

      setInterval(function(){
        if (!inference) { return; }
        if (infering) { return; }
        infering = true;
        inferFaceDetection(function(croppedCanvas, croppedFaceBox, next) {
          if (next == null) {
            infering = false;
            return;
          }

          inferFaceId(croppedCanvas, croppedFaceBox, function(name) {
            drawBoxWithText(croppedFaceBox, name);
            updateFaceList(croppedCanvas, name);
            next();
          });
        });
      }, 10);

      load();
    </script>
  </body>
</html>