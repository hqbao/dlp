{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "os.system('pip install dlp')\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import dlp.blocks as blocks\n",
        "import dlp.utils as utils\n",
        "\n",
        "def build_model():\n",
        "\ttensorNone = None\n",
        "\ttensor15 = None\n",
        "\ttensor1 = blocks.INPUT_LAYER(input_tensor=tensorNone, batch_size=1, input_shape=[512, 512, 3], dtype='float32')\n",
        "\ttensor2 = blocks.CONV2D_BLOCK(input_tensor=tensor1, filters=16, kernel_size=[3, 3], strides=[2, 2], padding='same', use_bias=1, trainable=1, bn_trainable=1, activation='relu', name='CONV2D_BLOCK0')\n",
        "\ttensor3 = blocks.MAXPOOL2D_LAYER(input_tensor=tensor2, pool_size=[3, 3], strides=[2, 2], padding='same')\n",
        "\ttensor4 = blocks.RESNET_SIDENTITY_BLOCK(input_tensor=tensor3, filters=[16, 16, 64], kernel_size=[3, 3], strides=[1, 1], use_bias=1, trainable=1, bn_trainable=1, name='RESNET_SIDENTITY_BLOCK0')\n",
        "\ttensor5 = blocks.RESNET_IDENTITY_BLOCK(input_tensor=tensor4, filters=[16, 16, 64], kernel_size=[3, 3], use_bias=1, trainable=1, bn_trainable=1, repeat=4, name='RESNET_IDENTITY_BLOCK0')\n",
        "\ttensor6 = blocks.RESNET_SIDENTITY_BLOCK(input_tensor=tensor5, filters=[32, 32, 128], kernel_size=[3, 3], strides=[2, 2], use_bias=1, trainable=1, bn_trainable=1, name='RESNET_SIDENTITY_BLOCK1')\n",
        "\ttensor7 = blocks.RESNET_IDENTITY_BLOCK(input_tensor=tensor6, filters=[32, 32, 128], kernel_size=[3, 3], use_bias=1, trainable=1, bn_trainable=1, repeat=4, name='RESNET_IDENTITY_BLOCK1')\n",
        "\ttensor8 = blocks.CONV2D_BLOCK(input_tensor=tensor7, filters=32, kernel_size=[3, 3], strides=[1, 1], padding='same', use_bias=1, trainable=1, bn_trainable=1, activation='relu', name='CONV2D_BLOCK1')\n",
        "\ttensor9 = blocks.CONV2D_LAYER(input_tensor=tensor8, name='CONV2D_LAYER0', filters=6, kernel_size=[3, 3], strides=[1, 1], padding='same', use_bias=1, trainable=1)\n",
        "\ttensor10 = blocks.RESHAPE_LAYER(input_tensor=tensor9, new_shape=[-1, 6])\n",
        "\ttensor11 = blocks.SPLIT_LAYER(input_tensor=tensor10, axis=-1, size_splits=[2, 4])\n",
        "\ttensor12 = blocks.SPLITTED_LAYER(input_tensor=tensor11, order=0)\n",
        "\ttensor14 = blocks.ACTIVATION_LAYER(input_tensor=tensor12, activation='linear')\n",
        "\ttensor15 = blocks.CONCAT_LAYER(tensor1=tensor15, tensor2=tensor14, axis=-1)\n",
        "\ttensor13 = blocks.SPLITTED_LAYER(input_tensor=tensor11, order=1)\n",
        "\ttensor15 = blocks.CONCAT_LAYER(tensor1=tensor15, tensor2=tensor13, axis=-1)\n",
        "\tloss_func16 = blocks.LOSS_FUNC_OD4(input_tensor=tensor15, name='SSD', total_classes=1, lamda=1)\n",
        "\tmodel = tf.keras.models.Model(inputs=tensor1, outputs=tensor15)\n",
        "\tmodel.compile(optimizer=tf.keras.optimizers.Adam(), loss=loss_func16)\n",
        "\treturn model\n",
        "\n",
        "def train(dataset_name, image_shape, scale_sizes, anchor_sizes, iou_thresholds, anchor_sampling, epochs):\n",
        "\tdataset_info = utils.get_dataset_info(dataset_name)\n",
        "\toutput_path = './outputs'\n",
        "\ttrain_anno_file_path = dataset_info['train_anno_file_path']\n",
        "\ttrain_image_dir_path = dataset_info['train_image_dir_path']\n",
        "\tishape = image_shape\n",
        "\tssize = scale_sizes\n",
        "\tasizes = anchor_sizes\n",
        "\ttotal_classes = dataset_info['total_classes']\n",
        "\ttotal_epoches = epochs\n",
        "\ttotal_train_examples = dataset_info['total_train_examples']\n",
        "\n",
        "\tabox_2dtensor = tf.constant(value=utils.genanchors(isize=ishape[:2], ssize=ssize, asizes=asizes), dtype='float32') # (h*w*k, 4)\n",
        "\n",
        "\tmodel = build_model()\n",
        "\tmodel.summary()\n",
        "\n",
        "\tif not os.path.exists(output_path):\n",
        "\t\tos.makedirs(output_path)\n",
        "\n",
        "\tweight_file_path = output_path+'/weights_'+dataset_name+'.h5'\n",
        "\tif os.path.isdir(weight_file_path):\n",
        "\t\tmodel.load_weights(weight_file_path, by_name=True)\n",
        "\n",
        "\ttrain_dataset = utils.load_object_detection_dataset(anno_file_path=train_anno_file_path, total_classes=total_classes)\n",
        "\n",
        "\tfor epoch in range(total_epoches):\n",
        "\t\tgen = utils.genxy_od(\n",
        "\t\t\tdataset=train_dataset, \n",
        "\t\t\timage_dir=train_image_dir_path, \n",
        "\t\t\tishape=ishape, \n",
        "\t\t\tabox_2dtensor=abox_2dtensor, \n",
        "\t\t\tiou_thresholds=iou_thresholds, \n",
        "\t\t\ttotal_examples=total_train_examples,\n",
        "\t\t\ttotal_classes=total_classes, \n",
        "\t\t\tanchor_sampling=anchor_sampling)\n",
        "\n",
        "\t\tprint('\\nTrain epoch {}'.format(epoch))\n",
        "\t\tloss = np.zeros(total_train_examples)\n",
        "\n",
        "\t\tfor batch in range(total_train_examples):\n",
        "\t\t\tbatchx_4dtensor, batchy_2dtensor, _ = next(gen)\n",
        "\t\t\tbatch_loss = model.train_on_batch(batchx_4dtensor, batchy_2dtensor)\n",
        "\t\t\tloss[batch] = batch_loss\n",
        "\n",
        "\t\t\tprint('-', end='')\n",
        "\t\t\tif batch%100==99:\n",
        "\t\t\t\tprint('{:.2f}%'.format((batch+1)*100/total_train_examples), end='\\n')\n",
        "\n",
        "\t\tmean_loss = float(np.mean(loss, axis=-1))\n",
        "\t\tprint('\\nLoss: {:.3f}'.format(mean_loss))\n",
        "\n",
        "\t\tmodel.save_weights(weight_file_path)\n",
        "\n",
        "train(dataset_name=\"face1024\", image_shape=[512, 512, 3], scale_sizes=[64, 64], anchor_sizes=[[32, 32]], iou_thresholds=[0.3, 0.5], anchor_sampling=100, epochs=1000)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}